{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8919469-d9d6-4500-add7-559f50910041",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from datetime import datetime\n",
    "import os\n",
    "from google.cloud import storage\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Create a client to access the GCS bucket\n",
    "client = storage.Client.from_service_account_json('key.json')\n",
    "\n",
    "# Define the bucket name and directory path\n",
    "bucket_name = \"airbnb_data_2022\"\n",
    "directory_path = \"files/\"\n",
    "\n",
    "# Get the bucket\n",
    "bucket = client.get_bucket(bucket_name)\n",
    "\n",
    "# Get the blobs in the directory\n",
    "blobs = bucket.list_blobs(prefix=directory_path)\n",
    "\n",
    "# Initialize Spark Session\n",
    "spark = SparkSession.builder.appName(\"GCS to GCS\").config(\"spark.executor.instances\", \"16\") \\\n",
    "    .config(\"spark.executor.memory\", \"16g\") \\\n",
    "    .config(\"spark.driver.memory\", \"16g\") \\\n",
    "    .config(\"spark.sql.execution.arrow.enabled\", \"true\").getOrCreate()\n",
    "\n",
    "spark._jsc.hadoopConfiguration().set(\"google.cloud.auth.service.account.json.keyfile\",\"key.json\")\n",
    "\n",
    "# Define bucket names\n",
    "source_bucket = \"airbnb_data_2022\"\n",
    "target_bucket = \"zoomcamp_us\"\n",
    "\n",
    "backfill = 'yes'\n",
    "backfill_list = ['mar', 'jun', 'sep', 'dec']\n",
    "\n",
    "if backfill == 'yes':\n",
    "    for i in backfill_list:\n",
    "        # Extract the file names from the blobs\n",
    "        listing_files = [obj.name for obj in client.list_blobs(bucket_name, prefix=\"files/\") if \"listings\" in obj.name and i in obj.name and obj.name.endswith(\".csv\")]\n",
    "        non_listing_files = [obj.name for obj in client.list_blobs(bucket_name, prefix=\"files/\") if \"listings\" not in obj.name and i in obj.name and obj.name.endswith(\".csv\")]\n",
    "\n",
    "        # Load listing files into a dataframe\n",
    "        listing_df = spark.read.format(\"csv\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"delimiter\", \",\") \\\n",
    "            .option(\"multiLine\", \"true\") \\\n",
    "            .option(\"quote\", \"\\\"\") \\\n",
    "            .option(\"escape\", \"\\\"\") \\\n",
    "            .load([f\"gs://{source_bucket}/{file_name}\" for file_name in listing_files]) \\\n",
    "            .withColumn(\"filename\", F.input_file_name())\n",
    "\n",
    "        non_listing_df = spark.read.format(\"csv\") \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"delimiter\", \",\") \\\n",
    "            .option(\"multiLine\", \"true\") \\\n",
    "            .option(\"quote\", \"\\\"\") \\\n",
    "            .option(\"escape\", \"\\\"\") \\\n",
    "            .load([f\"gs://{source_bucket}/{file_name}\" for file_name in non_listing_files]) \\\n",
    "            .withColumn(\"filename\", F.input_file_name())  \n",
    "        \n",
    "        # Replace the string \"\"[\"...,...\"]\"\" with \"...,...\"\n",
    "        listing_df = listing_df.select([F.regexp_replace(c, r'^\\\"\\\"\\[(.*)\\]\\\"\\\"$', '$1').alias(c) if t == 'string' else c for c, t in listing_df.dtypes])\n",
    "        non_listing_df = non_listing_df.select([F.regexp_replace(c, r'^\\\"\\\"\\[(.*)\\]\\\"\\\"$', '$1').alias(c) if t == 'string' else c for c, t in non_listing_df.dtypes])\n",
    "\n",
    "        # Write the listing dataframe to the target bucket\n",
    "        destination_path = f\"gs://{target_bucket}/files/listings/{i}\"\n",
    "        destination_path_non = f\"gs://{target_bucket}/files/non_listings/{i}\"\n",
    "\n",
    "        listing_df.write \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"delimiter\", \",\") \\\n",
    "            .option(\"quote\", \"\\\"\") \\\n",
    "            .option(\"escape\", \"\\\"\") \\\n",
    "            .option(\"multiLine\", \"false\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .csv(destination_path)\n",
    "        \n",
    "        non_listing_df.write \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"delimiter\", \",\") \\\n",
    "            .option(\"quote\", \"\\\"\") \\\n",
    "            .option(\"escape\", \"\\\"\") \\\n",
    "            .option(\"multiLine\", \"false\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .csv(destination_path_non)\n",
    "\n",
    "else:\n",
    "    listing_files = [obj.name for obj in client.list_blobs(bucket_name, prefix=\"files/\") if \"listings\" in obj.name and obj.name.endswith(\".csv\")]\n",
    "    non_listing_files = [obj.name for obj in client.list_blobs(bucket_name, prefix=\"files/\") if \"listings\" not in obj.name and obj.name.endswith(\".csv\")]\n",
    "    listing_df = listing_df.select([F.regexp_replace(c, r'^\\\"\\\"\\[(.*)\\]\\\"\\\"$', '$1').alias(c) if t == 'string' else c for c, t in listing_df.dtypes])\n",
    "    non_listing_df = non_listing_df.select([F.regexp_replace(c, r'^\\\"\\\"\\[(.*)\\]\\\"\\\"$', '$1').alias(c) if t == 'string' else c for c, t in non_listing_df.dtypes])\n",
    "    destination_path = f\"gs://{target_bucket}/files/listings/\"\n",
    "    destination_path_non = f\"gs://{target_bucket}/files/non_listings/\"\n",
    "    listing_df.write \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"delimiter\", \",\") \\\n",
    "            .option(\"quote\", \"\\\"\") \\\n",
    "            .option(\"escape\", \"\\\"\") \\\n",
    "            .option(\"multiLine\", \"false\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .csv(destination_path)\n",
    "        \n",
    "    non_listing_df.write \\\n",
    "            .option(\"header\", \"true\") \\\n",
    "            .option(\"delimiter\", \",\") \\\n",
    "            .option(\"quote\", \"\\\"\") \\\n",
    "            .option(\"escape\", \"\\\"\") \\\n",
    "            .option(\"multiLine\", \"false\") \\\n",
    "            .mode(\"overwrite\") \\\n",
    "            .csv(destination_path_non)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2de3f940-e9ed-421d-85f6-836bf73af4bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
